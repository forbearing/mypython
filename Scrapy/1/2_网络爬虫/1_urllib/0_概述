request
	它是最基本的 HTTP 请求模块，可以用来模拟发送请求。就像在浏览器里输入网址然后回车一样，只需要
	给库方法传入 URL 以及额外的参数，就可以模拟实现这个过程了。

error
	异常处理模块，如果出现请求错误，我们可以捕获这些异常，然后进行重试或其他操作以保证程序不会
	意外终止

parse
	一个工具模块，提供了许多 URL 处理方式，比如拆分、解藕、合并等

robotparser
	主要用来识别网站的 robots.txt 文件，然后判断哪些网站可以爬，哪些网站不可以爬，
	它其实用的比较少。
